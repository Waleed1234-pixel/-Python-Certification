{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<center> <h3 style=\"color:blue\">========================================================</h3> </center>\n",
    "<center> <h3 style=\"color:green\">In the Name of Allah, the Most Beneficent, the Most Merciful</h3> </center>\n",
    "<center> <h3 style=\"color:blue\">========================================================</h3> </center>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        *----------------------------- AUTHOR_DETAILS -------------------------------*\n",
    "        |                                                                            |\n",
    "        |        Project Title  = Heart Health Predictor                             |\n",
    "        |                                                                            |\n",
    "        |        Author         = Muhammed Waleed Khawaja                            |\n",
    "        |                                                                            |\n",
    "        |                                                                            |\n",
    "        |                                                                            |\n",
    "        |                                                                            |\n",
    "        |                                                                            |\n",
    "        |                                                                            |\n",
    "        |                                                                            |\n",
    "        *----------------------------------------------------------------------------*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<center> <h2 style=\"color:green\">-------------------- PROJECT PURPOSE --------------------</h2> </center>\n",
    "<br>\n",
    "<center><h3>\n",
    "The main purpose of this Project is to demonstrate how the Heart Disease Occurance Problem can be treated as a Supervised Machine Learning Problem using Python and Scikit-learn Machine Learning Toolkit </h3>\n",
    "<br>\n",
    "<center><h3> For this Purpose, In Sha Allah, we will execute the Machine Learning Cycle </h3>\n",
    "<br>\n",
    "<center> <h2 style=\"color:green\">-------------------------------------------------------------------------</h2> </center>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\"><strong>Heart Health Predictor â€“ Machine Learning Cycle</strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Cycle\n",
    "\n",
    "### Four phases of a Machine Learning Cycle are\n",
    "\n",
    "### Training Phase\n",
    "\n",
    "    Build the Model using Training Data\n",
    "\n",
    "### Testing Phase\n",
    "\n",
    "     Evaluate the performance of Model using Testing Data\n",
    "\n",
    "### Application Phase\n",
    "\n",
    "     Deploy the Model in the Real-world, to predict Real-time unseen Data\n",
    "\n",
    "### Feedback Phase\n",
    "\n",
    "    Take Feedback from the Users and Domain Experts to improve the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\">Executing Machine Learning Cycle Using a Single File</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Sha Allah, we will follow the following steps to execute the Machine Learning Cycle Using a Single File\n",
    "\n",
    "#### Step 1: Import Libraries\n",
    "\n",
    "#### Step 2: Load Sample Data\n",
    "\n",
    "#### Step 3: Understand and Pre-process Sample Data\n",
    "    \n",
    "    Step 3.1: Understand Sample Data\n",
    "    \n",
    "    Step 3.2: Pre-process Sample Data\n",
    "\n",
    "#### Step 4: Feature Extraction \n",
    "\n",
    "   \n",
    "\n",
    "#### Step 5: Execute the Training Phase\n",
    "\n",
    "    Step 5.1: Splitting Input Vectors and Outputs / Labels and features specifically\n",
    "\n",
    "    Step 5.2: Splitting into Training and Testing Data.\n",
    "\n",
    "    Step 5.3: Train the Support Vector Classifier and Random Forest seperately\n",
    "\n",
    "    Step 5.4: Save the Trained Models\n",
    "\n",
    "#### Step 6: Execute the Testing Phase \n",
    "\n",
    "    Step 6.1: Splitting Input Vectors and Outputs/Labels of Testing Data\n",
    "    \n",
    "    Step 6.2: Load the Saved Model\n",
    "    \n",
    "    Step 6.3: Evaluate the Performance of Trained Model\n",
    "\n",
    "        Step 6.3.1: Make Predictions with the Trained Model on Testing Data\n",
    "\n",
    "    Step 6.4: Calculate the Accuracy Score\n",
    "\n",
    "#### Step 7: Execute the Application Phase \n",
    "\n",
    "    Step 7.1: Take Input from User \n",
    "\n",
    "    Step 7.2: Convert User Input into Feature Vector (Exactly Same as Feature Vectors of Sample Data)\n",
    "\n",
    "    Step 7.3: Load the Saved Model\n",
    "\n",
    "    Step 7.4: Model Prediction\n",
    "\n",
    "         Step 8.5.1: Apply Model on the  unseen instance and return Prediction to the User\n",
    "\n",
    "#### Step 9: Execute the Feedback Phase \n",
    "\n",
    "#### Step 10: Improve the Model based on Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: prettytable in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (3.11.0)\n",
      "Requirement already satisfied: astropy in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (6.1.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from prettytable) (0.2.13)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from astropy) (1.26.4)\n",
      "Requirement already satisfied: pyerfa>=2.0.1.1 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from astropy) (2.0.1.4)\n",
      "Requirement already satisfied: astropy-iers-data>=0.2024.8.27.10.28.29 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from astropy) (0.2024.10.28.0.34.7)\n",
      "Requirement already satisfied: PyYAML>=3.13 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from astropy) (6.0.2)\n",
      "Requirement already satisfied: packaging>=19.0 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from astropy) (23.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "*__________________________ *\n",
    "|Install necessary libraries|\n",
    "|__________________________ |\n",
    "*                           *\n",
    "'''\n",
    "\n",
    "%pip install prettytable astropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from prettytable import PrettyTable   \n",
    "from astropy.table import Table, Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n*-----------------------Method Used-----------------------*\\n|                                                         |\\n|     Function: read_csv()                                |                        \\n|             Purpose: Read a dataset in CSV file format  |\\n|     Arguments:                                          |\\n|             path: Path to dataset file                  |\\n|             dataset: Dataset file name                  |\\n|     Return:                                             |\\n|             dataset: Dataset in DataFrame format        |                     \\n|                                                         |\\n|                                                         |\\n|                                                         |\\n*_________________________________________________________*\\n\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "*---------------------- LOAD_SAMPLE_DATA ------------------------*\n",
    "|     # Loaded the heart disease dataset from a CSV file using the Pandas library.\n",
    "- During this step, specific features relevant to the analysis were selected to streamline the dataset. The selected features are:\n",
    "- `age`: Age of the patient\n",
    "- `sex`: Gender of the patient\n",
    "- `cp`: Chest pain type\n",
    "- `oldpeak': ST Depression Induced by Exercise.\n",
    "|\n",
    "*----------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "'''\n",
    "*-----------------------Method Used-----------------------*\n",
    "|                                                         |\n",
    "|     Function: read_csv()                                |                        \n",
    "|             Purpose: Read a dataset in CSV file format  |\n",
    "|     Arguments:                                          |\n",
    "|             path: Path to dataset file                  |\n",
    "|             dataset: Dataset file name                  |\n",
    "|     Return:                                             |\n",
    "|             dataset: Dataset in DataFrame format        |                     \n",
    "|                                                         |\n",
    "|                                                         |\n",
    "|                                                         |\n",
    "*_________________________________________________________*\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated Sample Data (first few rows):\n",
      "==========================================\n",
      "    age  sex  cp  oldpeak  target\n",
      "0    63    1   3      2.3       1\n",
      "1    37    1   2      3.5       1\n",
      "2    41    0   1      1.4       1\n",
      "3    56    1   1      0.8       1\n",
      "4    57    0   0      0.6       1\n",
      "5    57    1   0      0.4       1\n",
      "6    56    0   1      1.3       1\n",
      "7    44    1   1      0.0       1\n",
      "8    52    1   2      0.5       1\n",
      "9    57    1   2      1.6       1\n",
      "10   54    1   0      1.2       1\n",
      "11   48    0   2      0.2       1\n",
      "12   49    1   1      0.6       1\n",
      "13   64    1   3      1.8       1\n",
      "14   58    0   3      1.0       1\n",
      "15   50    0   2      1.6       1\n",
      "16   58    0   2      0.0       1\n",
      "17   66    0   3      2.6       1\n",
      "18   43    1   0      1.5       1\n",
      "19   69    0   3      1.8       1\n",
      "20   59    1   0      0.5       1\n",
      "21   44    1   2      0.4       1\n",
      "22   42    1   0      0.0       1\n",
      "23   61    1   2      1.0       1\n",
      "24   40    1   3      1.4       1\n",
      "25   71    0   1      0.4       1\n",
      "26   59    1   2      1.6       1\n",
      "27   51    1   2      0.6       1\n",
      "28   65    0   2      0.8       1\n",
      "29   53    1   2      1.2       1\n",
      "30   41    0   1      0.0       1\n",
      "31   65    1   0      0.4       1\n",
      "32   44    1   1      0.0       1\n",
      "33   54    1   2      0.5       1\n",
      "34   51    1   3      1.4       1\n",
      "35   46    0   2      1.4       1\n",
      "36   54    0   2      0.0       1\n",
      "37   54    1   2      1.6       1\n",
      "38   65    0   2      0.8       1\n",
      "39   65    0   2      0.8       1\n",
      "40   51    0   2      1.5       1\n",
      "41   48    1   1      0.2       1\n",
      "42   45    1   0      3.0       1\n",
      "43   53    0   0      0.4       1\n",
      "44   39    1   2      0.0       1\n",
      "45   52    1   1      0.2       1\n",
      "46   44    1   2      0.0       1\n",
      "47   47    1   2      0.0       1\n",
      "48   53    0   2      0.0       1\n",
      "49   53    0   0      0.0       1\n",
      "50   67    1   0      1.5       0\n",
      "51   67    1   0      2.6       0\n",
      "52   62    0   0      3.6       0\n",
      "53   63    1   0      1.4       0\n",
      "54   53    1   0      3.1       0\n",
      "55   56    1   2      0.6       0\n",
      "56   48    1   1      1.0       0\n",
      "57   58    1   1      1.8       0\n",
      "58   58    1   2      3.2       0\n",
      "59   60    1   0      2.4       0\n",
      "60   40    1   0      2.0       0\n",
      "61   60    1   0      1.4       0\n",
      "62   64    1   2      0.0       0\n",
      "63   43    1   0      2.5       0\n",
      "64   57    1   0      0.6       0\n",
      "65   55    1   0      1.2       0\n",
      "66   65    0   0      1.0       0\n",
      "67   61    0   0      0.0       0\n",
      "68   58    1   2      2.5       0\n",
      "69   50    1   0      2.6       0\n",
      "70   44    1   0      0.0       0\n",
      "71   60    1   0      1.4       0\n",
      "72   54    1   0      2.2       0\n",
      "73   50    1   2      0.6       0\n",
      "74   41    1   0      0.0       0\n",
      "75   51    0   0      1.2       0\n",
      "76   58    1   0      2.2       0\n",
      "77   54    1   0      1.4       0\n",
      "78   60    1   0      2.8       0\n",
      "79   60    1   2      3.0       0\n",
      "80   59    1   0      3.4       0\n",
      "81   46    1   2      3.6       0\n",
      "82   67    1   0      0.2       0\n",
      "83   62    1   0      1.8       0\n",
      "84   65    1   0      0.6       0\n",
      "85   44    1   0      0.0       0\n",
      "86   60    1   0      2.8       0\n",
      "87   58    1   0      0.8       0\n",
      "88   68    1   2      1.6       0\n",
      "89   62    0   0      6.2       0\n",
      "90   52    1   0      0.0       0\n",
      "91   59    1   0      1.2       0\n",
      "92   60    0   0      2.6       0\n",
      "93   49    1   2      2.0       0\n",
      "94   59    1   0      0.0       0\n",
      "95   57    1   2      0.4       0\n",
      "96   61    1   0      3.6       0\n",
      "97   39    1   0      1.2       0\n",
      "98   61    0   0      1.0       0\n",
      "99   56    1   0      1.2       0\n",
      "\n",
      "Full Sample Data:\n",
      "==================\n",
      "    age  sex  cp  oldpeak  target\n",
      "0    63    1   3      2.3       1\n",
      "1    37    1   2      3.5       1\n",
      "2    41    0   1      1.4       1\n",
      "3    56    1   1      0.8       1\n",
      "4    57    0   0      0.6       1\n",
      "5    57    1   0      0.4       1\n",
      "6    56    0   1      1.3       1\n",
      "7    44    1   1      0.0       1\n",
      "8    52    1   2      0.5       1\n",
      "9    57    1   2      1.6       1\n",
      "10   54    1   0      1.2       1\n",
      "11   48    0   2      0.2       1\n",
      "12   49    1   1      0.6       1\n",
      "13   64    1   3      1.8       1\n",
      "14   58    0   3      1.0       1\n",
      "15   50    0   2      1.6       1\n",
      "16   58    0   2      0.0       1\n",
      "17   66    0   3      2.6       1\n",
      "18   43    1   0      1.5       1\n",
      "19   69    0   3      1.8       1\n",
      "20   59    1   0      0.5       1\n",
      "21   44    1   2      0.4       1\n",
      "22   42    1   0      0.0       1\n",
      "23   61    1   2      1.0       1\n",
      "24   40    1   3      1.4       1\n",
      "25   71    0   1      0.4       1\n",
      "26   59    1   2      1.6       1\n",
      "27   51    1   2      0.6       1\n",
      "28   65    0   2      0.8       1\n",
      "29   53    1   2      1.2       1\n",
      "30   41    0   1      0.0       1\n",
      "31   65    1   0      0.4       1\n",
      "32   44    1   1      0.0       1\n",
      "33   54    1   2      0.5       1\n",
      "34   51    1   3      1.4       1\n",
      "35   46    0   2      1.4       1\n",
      "36   54    0   2      0.0       1\n",
      "37   54    1   2      1.6       1\n",
      "38   65    0   2      0.8       1\n",
      "39   65    0   2      0.8       1\n",
      "40   51    0   2      1.5       1\n",
      "41   48    1   1      0.2       1\n",
      "42   45    1   0      3.0       1\n",
      "43   53    0   0      0.4       1\n",
      "44   39    1   2      0.0       1\n",
      "45   52    1   1      0.2       1\n",
      "46   44    1   2      0.0       1\n",
      "47   47    1   2      0.0       1\n",
      "48   53    0   2      0.0       1\n",
      "49   53    0   0      0.0       1\n",
      "50   67    1   0      1.5       0\n",
      "51   67    1   0      2.6       0\n",
      "52   62    0   0      3.6       0\n",
      "53   63    1   0      1.4       0\n",
      "54   53    1   0      3.1       0\n",
      "55   56    1   2      0.6       0\n",
      "56   48    1   1      1.0       0\n",
      "57   58    1   1      1.8       0\n",
      "58   58    1   2      3.2       0\n",
      "59   60    1   0      2.4       0\n",
      "60   40    1   0      2.0       0\n",
      "61   60    1   0      1.4       0\n",
      "62   64    1   2      0.0       0\n",
      "63   43    1   0      2.5       0\n",
      "64   57    1   0      0.6       0\n",
      "65   55    1   0      1.2       0\n",
      "66   65    0   0      1.0       0\n",
      "67   61    0   0      0.0       0\n",
      "68   58    1   2      2.5       0\n",
      "69   50    1   0      2.6       0\n",
      "70   44    1   0      0.0       0\n",
      "71   60    1   0      1.4       0\n",
      "72   54    1   0      2.2       0\n",
      "73   50    1   2      0.6       0\n",
      "74   41    1   0      0.0       0\n",
      "75   51    0   0      1.2       0\n",
      "76   58    1   0      2.2       0\n",
      "77   54    1   0      1.4       0\n",
      "78   60    1   0      2.8       0\n",
      "79   60    1   2      3.0       0\n",
      "80   59    1   0      3.4       0\n",
      "81   46    1   2      3.6       0\n",
      "82   67    1   0      0.2       0\n",
      "83   62    1   0      1.8       0\n",
      "84   65    1   0      0.6       0\n",
      "85   44    1   0      0.0       0\n",
      "86   60    1   0      2.8       0\n",
      "87   58    1   0      0.8       0\n",
      "88   68    1   2      1.6       0\n",
      "89   62    0   0      6.2       0\n",
      "90   52    1   0      0.0       0\n",
      "91   59    1   0      1.2       0\n",
      "92   60    0   0      2.6       0\n",
      "93   49    1   2      2.0       0\n",
      "94   59    1   0      0.0       0\n",
      "95   57    1   2      0.4       0\n",
      "96   61    1   0      3.6       0\n",
      "97   39    1   0      1.2       0\n",
      "98   61    0   0      1.0       0\n",
      "99   56    1   0      1.2       0\n"
     ]
    }
   ],
   "source": [
    "selected_columns = ['age','sex','cp', 'oldpeak', 'target']\n",
    " \n",
    "sample_data = pd.read_csv(\"heart-disease-sample-data.csv\", usecols = selected_columns)\n",
    "'''\n",
    "---------------------------------------------------------------------------------------\n",
    "#usecols=selected_columns tells pandas to load only the specified columns from the file.\n",
    "----------------------------------------------------------------------------------------\n",
    "'''\n",
    "\n",
    "# Display the truncated version of the sample data\n",
    "print(\"Truncated Sample Data (first few rows):\")\n",
    "print(\"==========================================\")\n",
    "print(sample_data)\n",
    "\n",
    "# Set display options to show all rows and columns\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "# Display the full sample data\n",
    "print(\"\\nFull Sample Data:\")\n",
    "print(\"==================\")\n",
    "print(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Understand and Pre-process Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.1: Understand Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Attributes in Sample Data:\n",
      "==========================\n",
      "\n",
      "Index(['age', 'sex', 'cp', 'oldpeak', 'target'], dtype='object')\n",
      "\n",
      "\n",
      "Number of Instances in Sample Data: 100\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Understand Sample Data\n",
    "\n",
    "print(\"\\n\\nAttributes in Sample Data:\")\n",
    "print(\"==========================\\n\")\n",
    "\n",
    "print(sample_data.columns)\n",
    "\n",
    "print(\"\\n\\nNumber of Instances in Sample Data:\",sample_data[\"age\"].count())\n",
    "print(\"========================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.2: Pre-process Sample Data\n",
    "  \n",
    "    3.2.1 Outliers detection:\n",
    "    \n",
    "    o age: Ranges from 39 to 71, which is reasonable.\n",
    "    o sex: Has only two values, 0 and 1, representing binary categories (likely male and female), so no outliers here.\n",
    "    o cp (Chest Pain Type): Values range from 0 to 3, suggesting categorical data with four possible levels. All values fall within this expected range, so no outliers.\n",
    "    o target: Binary values 0 and 1 likely represent the presence or absence of a condition (e.g., heart disease). As with sex, no outliers exist here.\n",
    "\n",
    "    o oldpeak:\n",
    " In this analysis, the value of 6.2 in the 'oldpeak' feature is considered an outlier. \n",
    " In the context of heart disease prediction, a normal range for 'oldpeak' typically falls between 0 and 5. Given this context, the value of 6.2 is more than one standard deviation above the expected maximum and may not represent a realistic scenario for the population under study.\n",
    "\n",
    "The decision to remove the entire row containing this outlier is justified due to the following reason:\n",
    "  **Minimal Impact**: This dataset contains a single observation with the outlier. Removing just one row is unlikely to have a significant effect on the overall performance or outcomes of the predictive model. In larger datasets, such a removal would be even less impactful.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n--------------------------------------------------------------------------Method Used----------------------------------------------------------------------------------------------------\\n\\n|df['oldpeak']: Accesses the oldpeak column of the DataSet.                                                                                                                        |\\n|.apply(lambda x: x <= threshold):                                                                                                                                                 |\\n|The apply method applies a function to each element in the oldpeak column.                                                                                                        |\\n|The lambda function checks if each value (x) is less than or equal to the threshold (5).                                                                                          | \\n|This returns a boolean Series where each value is True if the condition is met (the value is acceptable) and False if it is not (the value is an outlier).                        |\\n|Filtering: The sample data set  is filtered using this boolean Series to create a new data set, which only contains rows where oldpeak is less than or equal to 5 (no outlier).   |\\n\\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 1: Removing the row with the outlier using a lambda function\n",
    "threshold = 5\n",
    "new_sample_data = sample_data[sample_data['oldpeak'].apply(lambda x: x <= threshold)]\n",
    "\n",
    "new_sample_data\n",
    "\n",
    "\n",
    "'''\n",
    "--------------------------------------------------------------------------Method Used----------------------------------------------------------------------------------------------------\n",
    "\n",
    "|df['oldpeak']: Accesses the oldpeak column of the DataSet.                                                                                                                        |\n",
    "|.apply(lambda x: x <= threshold):                                                                                                                                                 |\n",
    "|The apply method applies a function to each element in the oldpeak column.                                                                                                        |\n",
    "|The lambda function checks if each value (x) is less than or equal to the threshold (5).                                                                                          | \n",
    "|This returns a boolean Series where each value is True if the condition is met (the value is acceptable) and False if it is not (the value is an outlier).                        |\n",
    "|Filtering: The sample data set  is filtered using this boolean Series to create a new data set, which only contains rows where oldpeak is less than or equal to 5 (no outlier).   |\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.2: Pre-process Sample Data Continuation\n",
    " 3.2.2 Handling missing values\n",
    "    o No null values identified\n",
    "\n",
    "    3.2.3 Feature Selection\n",
    "    o Already performed above during data loading.\n",
    "\n",
    "    3.2.4 Splitting data\n",
    "    o Down the line.\n",
    "\n",
    "    3.2.4 Encoding of categorical data\n",
    "    o Already done.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Feature Extraction\n",
    "    o\tFeatures are already Extracted\n",
    "    o\tNo Feature Extraction needs to be Performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Execute the Training Phase "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5.1: Splitting Input Vectors and Outputs / Labels and features specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Input Vectors and Outputs\n",
    "\n",
    "'''\n",
    "*---------------- SPLIT_INPUT_VECTORS_AND_LABELS --------------*\n",
    "|        Function: iloc()                                      |\n",
    "|            Purpose: Splitting Input Vector and Labels        |\n",
    "|        Arguments:                                            |\n",
    "|            Attribute: Name or Location Attribute to Split    |\n",
    "|        Return:                                               |\n",
    "|            Attribute: Split Attributes                       |\n",
    "*--------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = new_sample_data.iloc[:, :-1]  # Features\n",
    "y = new_sample_data.iloc[:, -1]     # Target\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5.2: Splitting into Training and Testing Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Data:\n",
      "==============\n",
      "\n",
      "    age  sex  cp  oldpeak  target\n",
      "43   53    0   0      0.4       1\n",
      "62   64    1   2      0.0       0\n",
      "3    56    1   1      0.8       1\n",
      "71   60    1   0      1.4       0\n",
      "45   52    1   1      0.2       1\n",
      "48   53    0   2      0.0       1\n",
      "6    56    0   1      1.3       1\n",
      "99   56    1   0      1.2       0\n",
      "82   67    1   0      0.2       0\n",
      "76   58    1   0      2.2       0\n",
      "60   40    1   0      2.0       0\n",
      "80   59    1   0      3.4       0\n",
      "90   52    1   0      0.0       0\n",
      "68   58    1   2      2.5       0\n",
      "51   67    1   0      2.6       0\n",
      "27   51    1   2      0.6       1\n",
      "18   43    1   0      1.5       1\n",
      "56   48    1   1      1.0       0\n",
      "63   43    1   0      2.5       0\n",
      "74   41    1   0      0.0       0\n",
      "1    37    1   2      3.5       1\n",
      "61   60    1   0      1.4       0\n",
      "42   45    1   0      3.0       1\n",
      "41   48    1   1      0.2       1\n",
      "4    57    0   0      0.6       1\n",
      "15   50    0   2      1.6       1\n",
      "17   66    0   3      2.6       1\n",
      "40   51    0   2      1.5       1\n",
      "38   65    0   2      0.8       1\n",
      "5    57    1   0      0.4       1\n",
      "91   59    1   0      1.2       0\n",
      "59   60    1   0      2.4       0\n",
      "0    63    1   3      2.3       1\n",
      "34   51    1   3      1.4       1\n",
      "28   65    0   2      0.8       1\n",
      "50   67    1   0      1.5       0\n",
      "11   48    0   2      0.2       1\n",
      "35   46    0   2      1.4       1\n",
      "23   61    1   2      1.0       1\n",
      "52   62    0   0      3.6       0\n",
      "10   54    1   0      1.2       1\n",
      "31   65    1   0      0.4       1\n",
      "66   65    0   0      1.0       0\n",
      "57   58    1   1      1.8       0\n",
      "79   60    1   2      3.0       0\n",
      "85   44    1   0      0.0       0\n",
      "32   44    1   1      0.0       1\n",
      "84   65    1   0      0.6       0\n",
      "14   58    0   3      1.0       1\n",
      "88   68    1   2      1.6       0\n",
      "19   69    0   3      1.8       1\n",
      "29   53    1   2      1.2       1\n",
      "49   53    0   0      0.0       1\n",
      "97   39    1   0      1.2       0\n",
      "98   61    0   0      1.0       0\n",
      "69   50    1   0      2.6       0\n",
      "20   59    1   0      0.5       1\n",
      "94   59    1   0      0.0       0\n",
      "72   54    1   0      2.2       0\n",
      "77   54    1   0      1.4       0\n",
      "25   71    0   1      0.4       1\n",
      "37   54    1   2      1.6       1\n",
      "81   46    1   2      3.6       0\n",
      "46   44    1   2      0.0       1\n",
      "39   65    0   2      0.8       1\n",
      "65   55    1   0      1.2       0\n",
      "58   58    1   2      3.2       0\n",
      "12   49    1   1      0.6       1\n",
      "70   44    1   0      0.0       0\n",
      "87   58    1   0      0.8       0\n",
      "36   54    0   2      0.0       1\n",
      "21   44    1   2      0.4       1\n",
      "83   62    1   0      1.8       0\n",
      "9    57    1   2      1.6       1\n",
      "96   61    1   0      3.6       0\n",
      "67   61    0   0      0.0       0\n",
      "64   57    1   0      0.6       0\n",
      "47   47    1   2      0.0       1\n",
      "44   39    1   2      0.0       1\n",
      "\n",
      "\n",
      "Testing Data:\n",
      "==============\n",
      "\n",
      "    age  sex  cp  oldpeak  target\n",
      "26   59    1   2      1.6       1\n",
      "86   60    1   0      2.8       0\n",
      "2    41    0   1      1.4       1\n",
      "55   56    1   2      0.6       0\n",
      "75   51    0   0      1.2       0\n",
      "93   49    1   2      2.0       0\n",
      "16   58    0   2      0.0       1\n",
      "73   50    1   2      0.6       0\n",
      "54   53    1   0      3.1       0\n",
      "95   57    1   2      0.4       0\n",
      "53   63    1   0      1.4       0\n",
      "92   60    0   0      2.6       0\n",
      "78   60    1   0      2.8       0\n",
      "13   64    1   3      1.8       1\n",
      "7    44    1   1      0.0       1\n",
      "30   41    0   1      0.0       1\n",
      "22   42    1   0      0.0       1\n",
      "24   40    1   3      1.4       1\n",
      "33   54    1   2      0.5       1\n",
      "8    52    1   2      0.5       1\n"
     ]
    }
   ],
   "source": [
    "# Splitting Sample Data into Training Data and Testing Data\n",
    "\n",
    "''' \n",
    "*------------------- SPLIT_SAMPLE_DATA ---------------------*\n",
    "|        Function: train_test_split()                       |\n",
    "|              Purpose: Split arrays or matrices into       |\n",
    "|                       random train and test subsets       |\n",
    "|        Arguments:                                         |\n",
    "|              arrays: sequence of indexables               |\n",
    "|              test_size: float or int                      |\n",
    "|        Return:                                            |\n",
    "|              splitting: list                              |\n",
    "*-----------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "# Combine X_train and y_train into a single DataFrame\n",
    "training_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Save the combined DataFrame to a single CSV file\n",
    "training_data.to_csv('training_data.csv', index=False)\n",
    "\n",
    "# Combine x_test and y_test into a single DF\n",
    "testing_data = pd.concat([X_test, y_test], axis = 1)\n",
    "\n",
    "#Save the combined testing DF to a single CSV file\n",
    "testing_data.to_csv('testing_data.csv', index = False)\n",
    "\n",
    "\n",
    "# print Training and Testing Data\n",
    "\n",
    "print(\"\\n\\nTraining Data:\")\n",
    "print(\"==============\\n\")\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(training_data)\n",
    "print(\"\\n\\nTesting Data:\")\n",
    "print(\"==============\\n\")\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3: Train the Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training the Support Vector Classifier on Training Data\n",
      "========================================================\n",
      "\n",
      "\n",
      "Parameters and their values:\n",
      "============================\n",
      "\n",
      "SVC(gamma='auto', random_state=0)\n"
     ]
    }
   ],
   "source": [
    "# Train the Support Vector Classifier\n",
    "\n",
    "'''\n",
    "*--------------- SUPPORT_VECTOR_CLASSIFIER ------------------*\n",
    "'''\n",
    "\n",
    "''' \n",
    "*--------------- TRAIN_SUPPORT_VECTOR_CLASSIFIER ------------------*\n",
    "|       Function: svm.SVC()                                        |\n",
    "|           Purpose: Train the Algorithm on Training Data          |\n",
    "|       Arguments:                                                 |\n",
    "|           Training Data: Provide Training Data to the Model      |\n",
    "|       Return:                                                    |\n",
    "|           Parameter: Model return the Training Parameters        |\n",
    "*------------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "print(\"\\n\\nTraining the Support Vector Classifier on Training Data\")\n",
    "print(\"========================================================\\n\")\n",
    "print(\"\\nParameters and their values:\")\n",
    "print(\"============================\\n\")\n",
    "svc_model = svm.SVC(gamma='auto',random_state=0)\n",
    "svc_model.fit(X_train,np.ravel(y_train))\n",
    "print(svc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training the Random Forest Classifier on Training Data\n",
      "========================================================\n",
      "\n",
      "\n",
      "Parameters and their values:\n",
      "============================\n",
      "\n",
      "RandomForestClassifier(random_state=0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "*--------------- RANDOM_FOREST_CLASSIFIER ------------------*\n",
    "'''\n",
    "print(\"\\n\\nTraining the Random Forest Classifier on Training Data\")\n",
    "print(\"========================================================\\n\")\n",
    "print(\"\\nParameters and their values:\")\n",
    "print(\"============================\\n\")\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_model.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Output the trained model's parameters\n",
    "print(rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5.4: Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n*--------------------------------------------------Further Elaboration---------------------------------------------------------------------*\\n\\n|pickle.dump() to \"write\" or \"save\" a model:                                                                                               |\\n\\n|o The pickle library converts the model object into a binary format.                                                                      |\\n o This binary representation is then saved to a file.\\n|o Later, we use pickle.load() to \"read\" the model back from the file. The model will be restored in the exact state it was when saved.    | \\n\\n|o This process is often referred to as serialization (saving) and deserialization (loading).                                              |\\n\\n*-------------------------------------------------------------------------------------------------------------------------------------------*\\n\\n'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the Trained Model\n",
    "\n",
    "'''\n",
    "*--------------- SUPPORT_VECTOR_CLASSIFIER ------------------*\n",
    "'''\n",
    "\n",
    "''' \n",
    "*--------------------- SAVE_THE_TRAINED_MODEL ---------------------*\n",
    "|        Function: dump()                                          |\n",
    "|             Purpose: Save the Trained Model on your Hard Disk    |\n",
    "|        Arguments:                                                |\n",
    "|             Model: Model Objects                                 |\n",
    "|        Return:                                                   |\n",
    "|             File: Trained Model will be Saved on Hard Disk       |\n",
    "*------------------------------------------------------------------* \n",
    "'''\n",
    "\n",
    "# Save the Model in a Pkl File\n",
    "\n",
    "pickle.dump(svc_model, open('svc_trained_model.pkl', 'wb'))\n",
    "\n",
    "\n",
    "'''\n",
    "*--------------------------------------------------Further Elaboration---------------------------------------------------------------------*\n",
    "\n",
    "|pickle.dump() to \"write\" or \"save\" a model:                                                                                               |\n",
    "\n",
    "|o The pickle library converts the model object into a binary format.                                                                      |\n",
    " o This binary representation is then saved to a file.\n",
    "|o Later, we use pickle.load() to \"read\" the model back from the file. The model will be restored in the exact state it was when saved.    | \n",
    "\n",
    "|o This process is often referred to as serialization (saving) and deserialization (loading).                                              |\n",
    "\n",
    "*-------------------------------------------------------------------------------------------------------------------------------------------*\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Trained Model\n",
    "'''\n",
    "*--------------- RANDOM_FOREST_CLASSIFIER ------------------*\n",
    "'''\n",
    "\n",
    "# Save the Model in a Pkl File\n",
    "\n",
    "pickle.dump(rf_model, open('rf_trained_model.pkl', 'wb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Execute the Testing Phase "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.1: Splitting Input Vectors and Outputs/Labels of Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Inputs Vectors (Feature Vectors) of Testing Data:\n",
      "=================================================\n",
      "\n",
      "    age  sex  cp  oldpeak\n",
      "26   59    1   2      1.6\n",
      "86   60    1   0      2.8\n",
      "2    41    0   1      1.4\n",
      "55   56    1   2      0.6\n",
      "75   51    0   0      1.2\n",
      "93   49    1   2      2.0\n",
      "16   58    0   2      0.0\n",
      "73   50    1   2      0.6\n",
      "54   53    1   0      3.1\n",
      "95   57    1   2      0.4\n",
      "53   63    1   0      1.4\n",
      "92   60    0   0      2.6\n",
      "78   60    1   0      2.8\n",
      "13   64    1   3      1.8\n",
      "7    44    1   1      0.0\n",
      "30   41    0   1      0.0\n",
      "22   42    1   0      0.0\n",
      "24   40    1   3      1.4\n",
      "33   54    1   2      0.5\n",
      "8    52    1   2      0.5\n",
      "\n",
      "\n",
      "Y_Test:\n",
      "==============================\n",
      "\n",
      " Target\n",
      "26    1\n",
      "86    0\n",
      "2     1\n",
      "55    0\n",
      "75    0\n",
      "93    0\n",
      "16    1\n",
      "73    0\n",
      "54    0\n",
      "95    0\n",
      "53    0\n",
      "92    0\n",
      "78    0\n",
      "13    1\n",
      "7     1\n",
      "30    1\n",
      "22    1\n",
      "24    1\n",
      "33    1\n",
      "8     1\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Splitting Input Vectors and Outputs/Labels of Testing Data\n",
    "\n",
    "'''\n",
    "*---------------- SPLIT_INPUT_VECTORS_AND_LABELS --------------*\n",
    "|        Function: iloc()                                      |\n",
    "|            Purpose: Splitting Input Vector and Labels        |\n",
    "|        Arguments:                                            |\n",
    "|            Attribute: Name or Location Attribute to Split    |\n",
    "|        Return:                                               |\n",
    "|            Attribute: Split Attributes                       |\n",
    "*--------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "print(\"\\n\\nInputs Vectors (Feature Vectors) of Testing Data:\")\n",
    "print(\"=================================================\\n\")\n",
    "X_Test = testing_data.iloc[: , :-1]\n",
    "print(X_Test)\n",
    "\n",
    "print(\"\\n\\nY_Test:\")\n",
    "print(\"==============================\\n\")\n",
    "print(\" Target\")\n",
    "Y_test = testing_data.iloc[: ,-1]\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.2: Load the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Saved Model\n",
    "\n",
    "'''\n",
    "*--------------- SUPPORT_VECTOR_CLASSIFIER ------------------*\n",
    "'''\n",
    "\n",
    "''' \n",
    "*------------------- LOAD_SAVED_MODEL --------------------------*\n",
    "|         Function: load()                                      |\n",
    "|               Purpose: Method to Load Previously Saved Model  |\n",
    "|         Arguments:                                            |\n",
    "|               Model: Trained Model                            |\n",
    "|         Return:                                               |\n",
    "|               File: Saved Model will be Loaded in Memory      |\n",
    "*---------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Load the Saved Model\n",
    "\n",
    "model = pickle.load(open('svc_trained_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Saved Model\n",
    "\n",
    "'''\n",
    "*--------------- RANDOM_FOREST_CLASSIFIER ------------------*\n",
    "'''\n",
    "model2 = pickle.load(open('rf_trained_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><strong>open('svc_trained_model.pkl', 'rb'):</strong></h1>\n",
    "\n",
    "<h2>This line of code opens the file named svc_trained_model.pkl in read-binary mode ('rb').<jh2>\n",
    "\n",
    "<h1><strong>pickle.load(...):</strong><h1>\n",
    "\n",
    "<h2>It converts (or \"deserializes\") this binary data back into the original Python object in our case the  trained machine learning model. The process known\n",
    "as <strong>Deserialization</strong>.</h2>\n",
    "\n",
    "<strong>The result is stored in the variable model, which now contains our trained SVC (Support Vector Classification) model and will be used for predictions.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.3: Evaluate the Machine Learning Model\n",
    "### Step 6.3.1: Make Predictions with the Trained Models on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Predictions Returned by svc_trained_model:\n",
      "==========================================\n",
      "\n",
      "    age  sex  cp  oldpeak  target  Predictions\n",
      "26   59    1   2      1.6       1            0\n",
      "86   60    1   0      2.8       0            0\n",
      "2    41    0   1      1.4       1            0\n",
      "55   56    1   2      0.6       0            1\n",
      "75   51    0   0      1.2       0            1\n",
      "93   49    1   2      2.0       0            1\n",
      "16   58    0   2      0.0       1            1\n",
      "73   50    1   2      0.6       0            1\n",
      "54   53    1   0      3.1       0            0\n",
      "95   57    1   2      0.4       0            1\n",
      "53   63    1   0      1.4       0            0\n",
      "92   60    0   0      2.6       0            0\n",
      "78   60    1   0      2.8       0            0\n",
      "13   64    1   3      1.8       1            1\n",
      "7    44    1   1      0.0       1            1\n",
      "30   41    0   1      0.0       1            0\n",
      "22   42    1   0      0.0       1            0\n",
      "24   40    1   3      1.4       1            1\n",
      "33   54    1   2      0.5       1            1\n",
      "8    52    1   2      0.5       1            1\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Machine Learning Model\n",
    "\n",
    "''' \n",
    "*--------------------- EVALUATE_MACHINE_LEARNING_MODEL ----------------------*\n",
    "|       Function: Predict()                                                  |\n",
    "|             Purpose: Make a Prediction using Algorithm on Test Data        |\n",
    "|       Arguments:                                                           |\n",
    "|            Testing Data: Provide Test data to the Trained Model            |\n",
    "|       Return:                                                              |\n",
    "|            Predictions: Model return Predictions                           |\n",
    "*----------------------------------------------------------------------------* \n",
    "'''\n",
    "\n",
    "# Provide Test data to the Trained Model\n",
    "\n",
    "model_predictions = model.predict(X_Test)\n",
    "\n",
    "'''\n",
    "*-------------------------------------------------------EXPLANATION--------------------------------------------------------------------------------*\n",
    "The above piece of code uses the trained machine learning model stored in the variable model to make predictions on the test data provided in X_Test. \n",
    "The predictions are stored in the variable model_predictions.\n",
    "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "'''\n",
    "testing_data_copy = testing_data.copy(deep=True)\n",
    "'''\n",
    "-------------------------------------------------EXPLANATION-----------------------------------------------\n",
    "The above piece of code creates a deep copy of testing_data and stores it in the variable testing_data_copy. \n",
    "-----------------------------------------------------------------------------------------------------------\n",
    "'''\n",
    "\n",
    "testing_data[\"Predictions\"] = model_predictions\n",
    "\n",
    "\n",
    "\n",
    "model_predictions = testing_data\n",
    "print(\"\\n\\nPredictions Returned by svc_trained_model:\")\n",
    "print(\"==========================================\\n\")\n",
    "print(model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Predictions Returned by svc_trained_model:\n",
      "==========================================\n",
      "\n",
      "    age  sex  cp  oldpeak  target  Predictions\n",
      "26   59    1   2      1.6       1            0\n",
      "86   60    1   0      2.8       0            0\n",
      "2    41    0   1      1.4       1            1\n",
      "55   56    1   2      0.6       0            1\n",
      "75   51    0   0      1.2       0            1\n",
      "93   49    1   2      2.0       0            1\n",
      "16   58    0   2      0.0       1            1\n",
      "73   50    1   2      0.6       0            1\n",
      "54   53    1   0      3.1       0            0\n",
      "95   57    1   2      0.4       0            1\n",
      "53   63    1   0      1.4       0            0\n",
      "92   60    0   0      2.6       0            0\n",
      "78   60    1   0      2.8       0            0\n",
      "13   64    1   3      1.8       1            1\n",
      "7    44    1   1      0.0       1            1\n",
      "30   41    0   1      0.0       1            1\n",
      "22   42    1   0      0.0       1            0\n",
      "24   40    1   3      1.4       1            1\n",
      "33   54    1   2      0.5       1            1\n",
      "8    52    1   2      0.5       1            1\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Machine Learning Model\n",
    "\n",
    "'''\n",
    "*--------------- RANDOM_FOREST_CLASSIFIER ------------------*\n",
    "'''\n",
    "# Provide Test data to the Trained Model\n",
    "\n",
    "model2_predictions = model2.predict(X_Test)\n",
    "\n",
    "\n",
    "testing_data_copy = testing_data.copy(deep=True)\n",
    "\n",
    "\n",
    "testing_data[\"Predictions\"] = model2_predictions\n",
    "\n",
    "# Save the Predictions into CSV File\n",
    "\n",
    "testing_data_copy.to_csv(r'model2-predictions.csv', index = False, header = True)\n",
    "\n",
    "model2_predictions = testing_data\n",
    "print(\"\\n\\nPredictions Returned by svc_trained_model:\")\n",
    "print(\"==========================================\\n\")\n",
    "print(model2_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.4: Calculate the Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Accuracy Score:\n",
      "===============\n",
      "\n",
      "0.65\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Accuracy Score\n",
    "\n",
    "''' \n",
    "/*------------------------ CALCULATE_ACCURACY_SCORE -------------------*\n",
    "|          Function: accuracy_score()                                  |\n",
    "|                Purpose: Evaluate the algorithm on Testing data       |\n",
    "|          Arguments:                                                  |\n",
    "|                Prediction: Predicted values                          |\n",
    "|                Label: Actual values                                  |\n",
    "|          Return:                                                     |\n",
    "|                Accuracy: Accuracy Score                              |\n",
    "*----------------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Calculate the Accuracy\n",
    "\n",
    "model_accuracy_score = accuracy_score(model_predictions[\"target\"],model_predictions[\"Predictions\"])\n",
    "\n",
    "print(\"\\n\\nAccuracy Score:\")\n",
    "print(\"===============\\n\")\n",
    "print(round(model_accuracy_score,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Accuracy Score:\n",
      "===============\n",
      "\n",
      "0.65\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Accuracy Score\n",
    "'''\n",
    "*--------------- RANDOM_FOREST_CLASSIFIER ------------------*\n",
    "'''\n",
    "\n",
    "# Calculate the Accuracy\n",
    "\n",
    "model2_accuracy_score = accuracy_score(model2_predictions[\"target\"],model2_predictions[\"Predictions\"])\n",
    "\n",
    "print(\"\\n\\nAccuracy Score:\")\n",
    "print(\"===============\\n\")\n",
    "print(round(model2_accuracy_score,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Execute the Application Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.1: Take Input from User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take Input from User\n",
    "\n",
    "''' \n",
    "*---------------- TAKE_USER_INPUT ----------------*\n",
    "'''\n",
    "\n",
    "age_input = input(\"\\nPlease enter your age here : \").strip()\n",
    "gender_input = input(\"\\nPlease enter your Gender here (1(Male), 0(Female)) : \").strip()\n",
    "cp_input = input(\"\\nPlease enter cp value : \").strip()\n",
    "oldpeak_input = input(\"\\nPlease enter oldpeak value : \").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.2: Convert User Input into Feature Vector (Exactly Same as Feature Vectors of Sample Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "User Input Feature Vector:\n",
      "==========================\n",
      "\n",
      "  age sex cp oldpeak\n",
      "0  55   1  4       5\n"
     ]
    }
   ],
   "source": [
    "# Convert User Input into Feature Vector\n",
    "\n",
    "user_input = pd.DataFrame({ 'age': [age_input],'sex': [gender_input],'cp': [cp_input],'oldpeak': [oldpeak_input]})\n",
    "\n",
    "print(\"\\n\\nUser Input Feature Vector:\")\n",
    "print(\"==========================\\n\")\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.3: Load the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Saved Model\n",
    "\n",
    "''' \n",
    "*----------------------- LOAD_SAVED_MODEL --------------------------*\n",
    "|         Function: load()                                          |\n",
    "|             Purpose: Method to Load Previously Saved Model        |\n",
    "|         Arguments:                                                |\n",
    "|               Model: Trained Model                                |\n",
    "|         Return:                                                   |\n",
    "|               File: Saved Model will be Loaded in Memory          |\n",
    "*-------------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Load the Saved Model\n",
    "\n",
    "model = pickle.load(open('rf_trained_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Saved Model\n",
    "\n",
    "''' \n",
    "*----------------------- LOAD_SAVED_MODEL --------------------------*\n",
    "|         Function: load()                                          |\n",
    "|             Purpose: Method to Load Previously Saved Model        |\n",
    "|         Arguments:                                                |\n",
    "|               Model: Trained Model                                |\n",
    "|         Return:                                                   |\n",
    "|               File: Saved Model will be Loaded in Memory          |\n",
    "*-------------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Load the Saved Model\n",
    "\n",
    "model2 = pickle.load(open('svc_trained_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.4: Model Prediction\n",
    "### Step 8.4.1: Apply Model on the Label Encoded Feature Vector of unseen instance and return Prediction to the User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|        ** Prediction **        |\n",
      "+--------------------------------+\n",
      "|            NEGATIVE            |\n",
      "+--------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Prediction of Unseen Instance\n",
    "\n",
    "''' \n",
    "*----------------------------  MODEL_PREDICTION --------------------------*\n",
    "|           Function: predict()                                           |\n",
    "|                 Purpose: Use Trained Model to Predict the Output        |\n",
    "|                          of Unseen Instances                            |\n",
    "|           Arguments:                                                    |\n",
    "|                 User Data: Label Encoded Feature Vector of              |\n",
    "|                            Unseen Instances                             |\n",
    "|           Return:                                                       |\n",
    "|                 Survival: Survived or Not Survived                      |\n",
    "*-------------------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Make a Prediction on Unseen Data\n",
    "\n",
    "\n",
    "\n",
    "user_input.rename(columns={\n",
    "    'Age': 'age',\n",
    "    'Gender': 'sex',\n",
    "    'Cp': 'cp',\n",
    "    'Oldpeak': 'oldpeak'\n",
    "}, inplace=True)\n",
    "predicted_survival = model.predict(user_input)\n",
    "\n",
    "if(predicted_survival == 1): \n",
    "    prediction = \"POSITIVE\"\n",
    "if(predicted_survival == 0):\n",
    "    prediction = \"NEGATIVE\"\n",
    "\n",
    "# Add the Prediction in a Pretty Table\n",
    "\n",
    "pretty_table = PrettyTable()\n",
    "pretty_table.add_column(\"       ** Prediction **       \",[prediction])\n",
    "print(pretty_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Execute the Feedback Phase\n",
    "## A Two-Step Process\n",
    "### Step 01: After some time, take Feedback from\n",
    "    o\tDomain Experts and Users on deployed Titanic Passenger Survival Prediction System\n",
    "### Step 02: Make a List of Possible Improvements based on Feedback received"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Improve Model based on Feedback\n",
    "### There is Always Room for Improvement\n",
    "### Based on Feedback from Domain Experts and Users\n",
    "    o\tImprove your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<center> <h3 style=\"color:blue\">==========================================================</h3> </center>\n",
    "<center> <h3 style=\"color:green\">JAZAK ALLAH KHAIR</h3> \n",
    "<center> <h3 style=\"color:blue\">==========================================================</h3> </center>\n",
    "<br><br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
